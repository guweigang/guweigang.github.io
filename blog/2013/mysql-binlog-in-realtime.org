#+TITLE:       mysql binlog in realtime
#+AUTHOR:      Gu Weigang
#+EMAIL:       guweigang@outlook.com
#+DATE:        2013-11-18 Mon
#+URI:         /blog/%y/%m/%d/mysql-binlog-in-realtime/
#+KEYWORDS:    mysql, binlog, mysql replication
#+TAGS:        mysql:php-binlog
#+LANGUAGE:    zh_CN
#+OPTIONS:     H:3 num:nil toc:nil \n:nil ::t |:t ^:nil -:nil f:t *:t <:t
#+DESCRIPTION: MySQL实时增量解析。



众所周知，MySQL是最受欢迎的互联网数据库（没有之一），它为开源而生。发展初期，很多公司都受益于其易用性和经济性。随着这些公司的成长，越来越多的公司投入到MySQL的开发中，因此MySQL的特性也越来越丰富，如：不同特性的存储引擎、Binlog主从复制方案等。

今天我们要探讨的就是如何实时解析MySQL Binlog，以及其所带来的巨大的业务价值。我可以在一瞬间说出很多应用场景，如：主从复制、缓存系统、检索引擎等。

#+BEGIN_CENTER
[[./binlog_app.png]]
#+END_CENTER

通常说来，在一个成熟的系统中我们有且仅有一份正确的全量数据（这里指MySQL中的数据）。而面对现在应用丰富的功能，MySQL并不能一直很好的满足我们。比如：我们需要使用缓存系统来加速服务，需要完备的检索系统来提供搜索服务，需要事件触发实时地发送通知等。但是摆在我们面前的问题是数据只有一份，且我们直接操作的都是MySQL，如何能让除MySQL之外的其他系统拥有同样的数据？且我们总是希望MySQL中的数据与其他系统的数据差异越小越好，越实时越好。当然我们可能会有一系列方案来解决这个问题，最典型的方法有两种：

 - 双写， 当你在更新MySQL的同时更新缓存系统、更新检索引擎，触发事件发送通知。这么做的确能解决问题，但是因为都是异构系统，没有一种机制能够保证写入成功。也就是说随着时间的推移，数据差异会越来越大。不仅如此，如果外部系统很多，这么做还会影响到主业务逻辑的响应时间。
   
 - 定时任务，在主业务逻辑中耦合更新其他系统的代码是不OK的，外部系统只有几个还行，如果要更新100个外部系统，这时候当如何处理呢？通过定时任务异步地去做这件事情看上去是一个更好的方案。的确如此，但是任务执行频率是多少呢？每1分钟？每10分钟？当然我们可以根据业务需要制定这个频率，乍想一下没啥问题，不过再想一下，定时任务具体用来做什么，消费业务维护的一个队列，或是每条数据都会有一个updateTime（on update CURRENT_TIMESTAMP）字段，通过扫表方式查找出每条被修改的数据？
   
   + 由业务端维护一个队列，就是说在业务端做操作的时候顺便把自己操作的内容写到队列里面去，然后由下游来消费这个队列。
    
     这种方式由业务端来维护操作记录，好处是能保证数据的业务完整性，坏处是在业务端耦合了非业务相关的逻辑，每当数据操作时都需要开启事务保证业务操作和操作日志都正确地写入，如果以后因为某些原因要直接操作DB，这种情况就很危险了，在操作DB时无法模拟复杂的业务逻辑计算和关系。

如果你使用这种方法，很可能会写出下面这段代码：
  
#+BEGIN_SRC PHP

$db = getDI()->get("test_db");
$db->begin();
$db->update("// logic operate");
$db->insert("// operate logs");
$db->commit();

#+END_SRC

而且很可能你设计的操作日志表会是这样子的：

#+BEGIN_CENTER
+----------+---------+------------+-------+------------+------+---------------------+
| event_id | user_id | object_id  | level | event_type | mcid | addtime             |
+----------+---------+------------+-------+------------+------+---------------------+
|      152 |      48 | 3007209739 |   200 |         23 |    0 | 2013-07-17 04:06:05 |
|      153 |      48 | 3007209739 |   202 |         24 |    0 | 0000-00-00 00:00:00 |
|      154 |      48 | 3007209739 |   201 |         24 |    0 | 0000-00-00 00:00:00 |
+----------+---------+------------+-------+------------+------+---------------------+
#+END_CENTER     

   + 扫表找出变更的记录，使用下面的SQL扫出某个时间点之后所有变化过的记录。这种方式解放了业务端，以一种更解耦的方式来处理增量变更，非常适合无状态缓存更新之类的场景。当然如果表记录数过大可能会有慢查询。但如果是有状态变化的数据，这种方式会丢失更新之前的数据。

#+BEGIN_SRC SQL
      SELECT * FROM `products` WHERE updateTime > '2013-11-12 12:00:00' ORDER BY updateTime LIMIT 1000;
#+END_SRC


下面我来介绍下，我们的应用场景，先看一张图：

#+BEGIN_CENTER
[[./app_arch.png]]
#+END_CENTER

